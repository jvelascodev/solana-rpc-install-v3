# Disk Mount Fix â€“ Documentation

> **âœ¨ General Note**: This fix works for **1â€‘3 data disks** in any configuration. The script automatically detects available disks and assigns them by priority (accountsâ€¯â†’â€¯ledgerâ€¯â†’â€¯snapshot) â€“ no manual configuration needed.

## ğŸš¨ Priorityâ€‘Order Issue (Autoâ€‘Fix)

### Symptoms

If you run `bash verify-mounts.sh` and see something like:

```
âš ï¸  Accounts not mounted separately (on the system disk)
âœ“ Ledger mounted separately on /dev/nvme0n1
âœ“ Snapshot mounted separately on /dev/nvme1n1
```

**This is a serious priority error!**
The *accounts* directory, which needs the highestâ€‘performance NVMe, is on the system disk, while the lowerâ€‘priority ledger and snapshot directories occupy the fast NVMe devices.

### âœ… Automatic Fix (Recommended)

The latest version of `1-prepare.sh` already supports automatic detection and correction of priority errors!

```bash
# Update to the latest version
cd /root/solana-rpc-install
git pull

# Run the preparation script â€“ it will fix the issue automatically
bash 1-prepare.sh
```

The script will automatically:

1. âœ… Detect the priority error  
2. âœ… Unmount the incorrectly mounted directories  
3. âœ… Clean old entries from `/etc/fstab`  
4. âœ… Remount disks in the correct priority order:  
   - **1st NVMe** â†’ *Accounts* (highest performance)  
   - **2nd NVMe** â†’ *Ledger* (medium performance)  
   - **3rd NVMe** â†’ *Snapshot* (low performance)  
5. âœ… Persist the new configuration

### ğŸ”§ Manual Fix (Alternative)

If you prefer granular control, you can use the dedicated fix script:

```bash
# 1. Stop the Solana node (if running)
systemctl stop sol

# 2. Run the priorityâ€‘fix script
cd /root/solana-rpc-install
bash fix-mount-priority.sh

# 3. Verify the result
bash verify-mounts.sh

# 4. Restart the node
systemctl start sol
```

### Why Does This Happen?

Possible causes:

1. Using an old script version (preâ€‘v1.0) where the diskâ€‘allocation logic was incomplete.  
2. Manually mounting disks in the wrong order.  
3. Migrating from another configuration without following the priority rules.

### Improvements in New Versions

**v1.1+ `1-prepare.sh`** now:

- âœ… Detects all available data disks automatically  
- âœ… Checks current mount status and priority  
- âœ… Fixes priority errors without user interaction  
- âœ… Handles any disk configuration (1â€‘3 data disks) intelligently

---

## ğŸ” Other Mountâ€‘Related Issues

### Detected Problems

Based on your disk layout and the output of `verify-mounts.sh`:

```
Current state:
- nvme0n1 (2.9â€¯TB) â†’ /mnt/nvme0n1  âŒ Wrong mount point
- nvme1n1 (2.9â€¯TB) â†’ /mnt/nvme1n1  âŒ Wrong mount point
- Accounts â†’ system disk /dev/mapper/vg0-root  âŒ Poor performance
- Ledger   â†’ system disk /dev/mapper/vg0-root  âŒ Poor performance
- Snapshot â†’ system disk /dev/mapper/vg0-root  âŒ Poor performance
```

#### Root Cause

The original `1-prepare.sh` had two major flaws:

1. **Skipping alreadyâ€‘mounted devices** â€“ it considered a device â€œdoneâ€ even if it was mounted in the wrong location, so the highâ€‘performance disks were never reâ€‘mounted.  
2. **No mountâ€‘point verification** â€“ it never checked whether a device was mounted at the expected target directory, so it could not autoâ€‘correct wrong mounts.

---

## âœ… Fix Details

### 1. Enhanced `mount_one()` Function

**Before**

```bash
mount_one() {
  local dev="$1"; local target="$2"
  if is_mounted_dev "$dev"; then
    echo "   - å·²æŒ‚è½½ï¼š$dev -> $(findmnt -no TARGET "$dev")ï¼Œè·³è¿‡"
    return 0
  fi
  # ... other logic
}
```

**After**

```bash
mount_one() {
  local dev="$1"; local target="$2"

  # Check if the device is already mounted
  if is_mounted_dev "$dev"; then
    local current_mount=$(findmnt -no TARGET "$dev")
    # If mounted to the correct target, skip
    if [[ "$current_mount" == "$target" ]]; then
      echo "   - å·²æ­£ç¡®æŒ‚è½½ï¼š$dev -> $targetï¼Œè·³è¿‡"
      return 0
    fi
    # If mounted elsewhere, unmount first
    echo "   - æ£€æµ‹åˆ° $dev æŒ‚è½½åœ¨é”™è¯¯ä½ç½®ï¼š$current_mount"
    echo "   - å¸è½½ $dev ..."
    umount "$dev"
    # Clean old fstab entry
    sed -i "\|$current_mount|d" /etc/fstab
  fi

  # Create target directory and mount
  mkdir -p "$target"
  mount -o defaults "$dev" "$target"

  # Update fstab
  sed -i "\|^${dev} |d" /etc/fstab
  echo "$dev $target ext4 defaults 0 0" >> /etc/fstab

  echo "   - âœ… æŒ‚è½½å®Œæˆï¼š$dev -> $target"
}
```

**Improvements**

- âœ… Verifies correct mount point before skipping  
- âœ… Automatically unmounts devices mounted in the wrong place  
- âœ… Cleans stale entries from `/etc/fstab`  
- âœ… Remounts to the proper target and persists the change

### 2. Optimized Deviceâ€‘Candidate Logic

**Helper** â€“ `is_correctly_mounted()`

```bash
# Returns 0 if the device is correctly mounted to one of the Solana data dirs
is_correctly_mounted() {
  local dev="$1"
  if ! is_mounted_dev "$dev"; then
    return 1  # not mounted
  fi
  local current_mount=$(findmnt -no TARGET "$dev")
  [[ "$current_mount" == "$ACCOUNTS" || "$current_mount" == "$LEDGER" || "$current_mount" == "$SNAPSHOT" ]]
}
```

**Candidate Selection (after the fix)**

```bash
# Gather candidate devices (exclude system disk; include wronglyâ€‘mounted devices)
CANDIDATES=()
for d in "${MAP_DISKS[@]}"; do
  disk="/dev/$d"
  [[ -n "$ROOT_DISK" && "$disk" == "$ROOT_DISK" ]] && continue
  parts=($(lsblk -n -o NAME,TYPE "$disk" | awk '$2=="part"{gsub(/^[â”œâ”€â””â”‚ ]*/, "", $1); print $1}'))
  if (( ${#parts[@]} == 0 )); then
    # Whole disk: add if not correctly mounted
    is_correctly_mounted "$disk" || CANDIDATES+=("$disk")
  else
    # Has partitions: pick the largest usable partition (not correctly mounted)
    best=""; best_size=0
    for p in "${parts[@]}"; do
      part="/dev/$p"
      is_correctly_mounted "$part" && continue
      size=$(lsblk -bno SIZE "$part")
      (( size > best_size )) && { best="$part"; best_size=$size; }
    done
    [[ -n "$best" ]] && CANDIDATES+=("$best")
  fi
done
```

**Improvements**

- âœ… Allows devices that are mounted incorrectly to reâ€‘enter the candidate pool  
- âœ… Skips only devices already correctly mounted to Solana directories  
- âœ… Handles both wholeâ€‘disk and partitionedâ€‘disk scenarios

---

## ğŸš€ Using the Fixed Script

### Execution Steps

1. **Important** â€“ Stop the Solana node before making any changes.  
2. Run the following (as root):

```bash
sudo su -
cd /root/solana-rpc-install
# Optional: backup current fstab
cp /etc/fstab /etc/fstab.backup
# Run the preparation script â€“ it now contains the fixes
bash 1-prepare.sh
```

### Expected Behaviour

The script adapts to your disk layout. Example for a **dualâ€‘disk** setup:

```
1. Detect disks â†’ candidates: /dev/nvme0n1 /dev/nvme1n1
2. Process nvme0n1 (Accounts priority)
   - Detected wrong mount at /mnt/nvme0n1
   - Unmounted, cleaned fstab entry
   - âœ… Mounted: /dev/nvme0n1 â†’ /root/sol/accounts
3. Process nvme1n1 (Ledger priority)
   - Detected wrong mount at /mnt/nvme1n1
   - Unmounted, cleaned fstab entry
   - âœ… Mounted: /dev/nvme1n1 â†’ /root/sol/ledger
4. Snapshot uses the system disk (no extra NVMe)
5. System optimizations (network tuning, etc.)
```

#### Other Scenarios

| Scenario | Mount Plan |
|----------|------------|
| **1 data disk** | Accounts â†’ NVMe, Ledger & Snapshot â†’ system disk |
| **2 data disks** (recommended) | Accounts â†’ NVMeâ€¯1, Ledger â†’ NVMeâ€¯2, Snapshot â†’ system disk |
| **3 data disks** | Accounts â†’ NVMeâ€¯1, Ledger â†’ NVMeâ€¯2, Snapshot â†’ NVMeâ€¯3, system disk only for OS |

### Verify the Result

After the script finishes, run:

```bash
bash verify-mounts.sh
```

**Expected output for a dualâ€‘disk configuration**:

```
[2] Checking mount points
--------------------------------------------
  â€¢ Accounts:
    - Path: /root/sol/accounts
    - Device: /dev/nvme0n1
    - Type: ext4
    - Mount point: /root/sol/accounts
    - Status: Independently mounted âœ“

  â€¢ Ledger:
    - Path: /root/sol/ledger
    - Device: /dev/nvme1n1
    - Type: ext4
    - Mount point: /root/sol/ledger
    - Status: Independently mounted âœ“

  â€¢ Snapshot:
    - Path: /root/sol/snapshot
    - Device: /dev/mapper/vg0-root
    - Type: ext4
    - Mount point: /
    - Status: On the root partition
```

Similar blocks are shown for singleâ€‘disk and threeâ€‘disk setups.

---

## âš ï¸ Precautions

### 1. Data Safety

- âœ… The script only manipulates mount points; it **does not delete or modify existing data**.  
- âœ… It detects existing filesystems and leaves them untouched.  
- âœ… Formatting occurs only on brandâ€‘new devices without a filesystem.

### 2. Unmount Failures

If a device cannot be unmounted (e.g., itâ€™s in use), the script will output:

```
âš ï¸  Unable to unmount /dev/nvme0n1 â€“ it may be in use. Please check manually and rerun the script.
```

**Resolution**:

```bash
# Find processes using the mount point
lsof | grep /mnt/nvme0n1
# Stop the offending service
systemctl stop <service-name>
# Manually unmount
umount /dev/nvme0n1
# Reâ€‘run the script
bash 1-prepare.sh
```

### 3. `/etc/fstab` Management

- âœ… Old mount entries are automatically removed.  
- âœ… New persistent entries are added, so the configuration survives reboots.

### 4. Systemâ€‘Disk Usage

Based on your hardware:

- **nvme0n1 (2.9â€¯TB)** â†’ `/root/sol/accounts` (highest IOPS)  
- **nvme1n1 (2.9â€¯TB)** â†’ `/root/sol/ledger` (medium IOPS)  
- **Snapshot** â†’ system disk (low IOPS)  

This allocation yields the best performanceâ€‘toâ€‘cost ratio.

---

## ğŸ¯ General Diskâ€‘Configuration Support

The script automatically adapts to **1â€‘3 data disks**:

### Configuration Scenarios

#### Scenarioâ€¯1 â€“ Single Data Disk

```
Configuration:
- Data Disk 1 â†’ /root/sol/accounts (high performance)
- System Disk â†’ /root/sol/ledger + /root/sol/snapshot
```

**Performance**: Accounts gets maximum IOPS; Ledger & Snapshot share the system disk.

#### Scenarioâ€¯2 â€“ Dual Data Disks (â­ Recommended)

```
Configuration:
- Data Disk 1 â†’ /root/sol/accounts
- Data Disk 2 â†’ /root/sol/ledger
- System Disk â†’ /root/sol/snapshot
```

**Performance**: Both Accounts and Ledger have independent NVMe, dramatically reducing systemâ€‘disk load.

#### Scenarioâ€¯3 â€“ Three Data Disks

```
Configuration:
- Data Disk 1 â†’ /root/sol/accounts
- Data Disk 2 â†’ /root/sol/ledger
- Data Disk 3 â†’ /root/sol/snapshot
- System Disk â†’ OS only
```

**Performance**: Full isolation; maximum throughput for all three directories.

### Performance Comparison

| Scenario | Accounts | Ledger | Snapshot | Systemâ€‘Disk Load | Costâ€‘Effectiveness |
|----------|----------|--------|----------|------------------|--------------------|
| **Before Fix** (all on system disk) | Shared | Shared | Shared | Very high | â€“ |
| **1â€¯Disk** | Dedicated NVMe âœ… | System disk | System disk | Medium | â˜…â˜…â˜… |
| **2â€¯Disks** | Dedicated NVMe âœ… | Dedicated NVMe âœ… | System disk | Low | â˜…â˜…â˜…â˜…â˜… |
| **3â€¯Disks** | Dedicated NVMe âœ… | Dedicated NVMe âœ… | Dedicated NVMe âœ… | Very low | â˜…â˜…â˜…â˜… |

### Space Utilisation (example: two 2.9â€¯TB NVMe)

- **Accounts**: 2.9â€¯TB (expected usage 300â€‘500â€¯GB)  
- **Ledger**: 2.9â€¯TB (can be limited to ~50â€¯GB via `--limit-ledger-size`)  
- **Snapshot**: Systemâ€‘disk space (50â€‘100â€¯GB, keep 2â€‘3 snapshots)

### Stability Improvements

- âœ… Reduces I/O pressure on the system disk (â€‘50â€¯% for singleâ€‘disk, â€‘80â€¯% for dualâ€‘disk)  
- âœ… Prevents Solana data from competing with system logs  
- âœ… Speeds up node sync and RPC response times  
- âœ… Lowers latency caused by diskâ€‘I/O saturation

---

## ğŸ“š Related Documentation

- **Mount Strategy**: `MOUNT_STRATEGY.md`  
- **Installation Guide**: `README.md`  
- **Performance Monitoring**: `bash performance-monitor.sh`  
- **Health Check**: `bash get_health.sh`

---

## ğŸ¤ Support & Feedback

If you encounter any issues while running the fix script:

1. Review the script output for specific error messages.  
2. Run `bash verify-mounts.sh` to inspect the current mount state.  
3. Reach out to technical support or open an Issue on the repository.

---

**Version**: 1.0  
**Last Updated**: 2025â€‘12â€‘01  
**Maintainer**: Solana RPC Team
